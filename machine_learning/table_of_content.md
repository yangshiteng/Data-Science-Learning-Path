# About Statistics

* [Statistical Miscellous Knowledge](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/statistical_miscellous_knowledge/table_of_content.md)

* [Probability Distribution](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/probability_distribution/table_of_content.md)

* [Hypothesis Test](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/hypothesis_test/table_of_content.md)

* [Statistical Theorem](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/statistical_theorem/table_of_content.md)

* [Permutation and Combination](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/permutation_and_combination/table_of_content.md)

* [Statistical Plot](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_statistics/statistical_plot/table_of_content.md)

# About Machine Learning

* [Machine Learning Miscellous Knowledge](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_machine_learning/machine_learning_miscellous_knowledge/table_of_content.md)

* [Gradient Descent in Machine Learning](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/about_machine_learning/gradient_descent/table_of_content.md)

# Supervised Learning (Classification and Regression)

* [Linear Regression](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/supervised_learning/linear_regression/table_of_content.md)


## 2. Logistic Regression
* [Logistic Regression](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/logistic_regression/Logistic_Regression.md)
* [Logistic Regression StatQuest Video 1](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/logistic_regression/logistic_regression_statquest.pdf)
* [Logistic Regression: Likelihood-based R-squared and P-value](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/logistic_regression/Logistic_Regression_Lilkelihood_based_Rsquared_and_Pvalue.pdf)
* [Logistic Regression: Saturated Model, Null Deviance and Residual Deviance](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/logistic_regression/Saturated_Model.pdf)
* [Introduction to Logistic Regression](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/logistic_regression/Introduction_to_logistic_regression.md)

## 3. Naive Bayes
* [Naive Bayes](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/naive_bayes/Naive_Bayes_statquest.md)
* [Naive Bayes Introduction](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/naive_bayes/Naive_Bayes_Introduction.md)

## 4. KNN
* [KNN (K-nearest Neighbors)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/knn/KNN.md)

## 5. Support Vector Machine
* [Support Vector Machine (StatQuest and Summary)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/Support_Vector_Machine.md)
* [Support Vector Machine and Kernel Tricks (StatQuest)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/SupportVectorMachine2.pdf)
* [SVM - Polynomial Kernel](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/SVM_Polynomial_Kernel.pdf)
* [SVM - Radial Basis Function (RBF) Kernel](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/RBF_kernel.pdf)
* [SVM - Q & A](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/SVM_QA.md)
* [SVM Detail](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/Support_Vector_Machine_Detail.md)
* [SVM Soft Margin and Kernel Tricks (kernel function is used to measure the similarity of two input vectors, it is just the dot production of two transformed input vectors)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/SVM_Soft_Margin_and_Kernel_Tricks.md)
* [SVM for Regression](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/SVR.md)
* [SVM for Anomaly Detection - Novelty Detection (One Class SVM)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/OneClassSVM.md)
* [Python Code for one class SVM](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/svm/One_Class_Support_Vector_Machine_(SVM)_For_Anomaly_Detection.ipynb)

## 6. Decision Tree
* [Classification and Regression Trees (CART)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/decision_tree/Classification_and_Regression_Trees.md)
* [Decision Tree Introduction](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/decision_tree/Decision_Tree_Introduction.md)
* [Tree Pruning (the Alpha is selected by Hyperparameter Tuning Techinque)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/decision_tree/Pruning_the_tree_model.md)

## 7. Ensemble Learning (集成学习)

### 7.1 Introduction

* [Ensemble Learning (集成学习)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Introduction/Ensemble_Learning.md)
* [Bagging 装袋算法 (Bootstrap Aggregatting 引导聚集算法)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Introduction/Bagging.md)
* [Boosting 提升算法](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Introduction/Boosting.md)
* [Bagging vs Boosting](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Introduction/Bagging_vs_Boosting.md)
* [Stacking 堆叠算法 (Stacked Generalization 堆叠泛化)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Introduction/stacking.md)

### 7.2 Ensemble Learning - Bagging

* [Random Forest (随机森林)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Bagging/random_forest/table_of_content.md)

### 7.3 Ensemble Learning - Boosting

* [AdaBoost (Adaptive Boosting 自适应提升算法) (Weight-based boosting algorithm)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Boosting/adaboost/table_of_content.md)

* [Gradient Boost (梯度提升算法) (Residual-based boosting algorithm)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Boosting/gradient_boost/table_of_content.md)


### 7.4 Ensemble Learning - Stacking

* [Stacking with Random Forest and CatBoost](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/machine_learning_models/Ensemble_Learning/Stacking/stacking_with_randomforest_and_catboost.md)

# Unsupervised Learning

* [Clustering](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/unsupervised_learning/clustering/table_of_content.md)

* [Novelty and Outlier Detection](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/unsupervised_learning/novelty_and_outlier_detection/table_of_content.md)

# Model Selection and Evaluation  

* [Metrics in Machine Learning](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/model_selection_and_evaluation/metrics/table_of_content.md)

* [Cross Validation](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/model_selection_and_evaluation/cross_validation/table_of_content.md)

* [Hyper-parameters Tuning](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/model_selection_and_evaluation/hypterparameter_tuning/table_of_content.md)

## Plotting


# Dimensionality Reduction

## Principal Component Analysis (PCA)
* [Principal Component Analysis (PCA) (Singular Value Decomposition SVD)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/dimension_reduction/statquest_pca_study_guide_v2.pdf)
* [Principal Component Analysis (PCA) (Eigen Decomposition of Covariance Matrix)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/dimension_reduction/PCA_BLOG.md)
* [PCA summary](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/machine_learning/dimension_reduction/PCA_summary.md)






