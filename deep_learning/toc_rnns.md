## III. Recurrent Neural Networks (RNNs)
- **Introduction to Recurrent Neural Networks**
  - [What are RNNs?](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/what_are_rnns.md)
  - [Applications of RNNs](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/rnns_application.md)
- **Basic RNN Architecture (Vanilla RNN)**
  - [Basic RNN Architecture (Vanilla RNN)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/basic_rnn_architecture.md)
  - [Recurrent Connections & Hidden States](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/recurrent_connection_hidden_state.md)
  - [Forward Propagation in RNNs](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/rnn_forward_prop.md)
  - [Backpropagation Through Time (BPTT)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/bptt.md)
  - [The Vanishing Gradient Problem](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/vanishing_gradient.md)
  - [The Exploding Gradient Problem](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/exploding_gradient.md)
  - [Short-term memory Problem](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/short_term_memory.md)
- **Building and Training RNNs**
  - [Overview of RNNs Training](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/rnn_training_overview.md)
  - [Loss Functions for Sequential Tasks](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/rnn_loss_function.md)
    - [CTC Loss](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/ctc_loss.md)
    - [Sequence-Level Loss](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/sequence_level_loss.md)
  - [Backpropagation Through Time (in detail)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/bptt_detail.md)
  - [Truncated BPTT](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/truncated_bptt.md)
  - [Gradient Clipping](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/gradient_clipping.md)
  - [Weight Initialization Strategies](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/weight_init.md)
  - [Optimizers for RNNs (SGD, Adam, RMSprop)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/rnn_optimizer.md)
  - [Regularization Techniques (Dropout, Zoneout)](https://github.com/yangshiteng/Data-Science-Learning-Path/blob/main/deep_learning/recurrent_neural_networks/regularization_rnns.md)
- **Evaluation of RNN Models**
  - [Perplexity (for language modeling)]()
  - [Accuracy, Precision, Recall]()
  - [Sequence-Level Metrics (BLEU, ROUGE)]()
  - [Visualizing Hidden States and Attention]()
- **Variants of RNN Cells**
  - [Long Short-Term Memory (LSTM)]()
  - [Gated Recurrent Units (GRUs)]()
  - [Vanilla RNN vs LSTM vs GRU]()
  - [Other Variants (IndRNN, ESN, UGRNN)]()
- **Architectures Built on Top of RNNs**
  - [Stacked (Deep) RNNs]()
  - [Bidirectional RNNs]()
  - [Hierarchical RNNs]()
  - [Encoderâ€“Decoder (Seq2Seq) Architecture]()
  - [Attention-Enhanced RNNs]()
  - [Pointer Networks]()
  - [Recurrent Attention Models (RAM)]()
  - [Memory-Augmented RNNs (NTM, DNC)]()
- **Applications of RNNs**
  - [Natural Language Processing]()
    - [Language Modeling]()
    - [Machine Translation]()
    - [Text Generation]()
    - [Named Entity Recognition (NER)]()
    - [Sentiment Analysis]()
  - [Speech Recognition]()
  - [Time Series Forecasting]()
  - [Music and Art Generation]()
  - [Video Analysis & Captioning]()
  - [Healthcare & Biomedical Data]()
  - [Recommendation Systems]()
  - [Robotics and Control Systems]()
- **Implementing RNNs in Practice**
  - [RNNs Implementation with TensorFlow & Keras]()
  - [RNNs Implementation with PyTorch]()
- **Beyond RNNs: Modern Alternatives**
  - [Self-Attention and Transformers]()
  - [Why Transformers Outperform RNNs]()
  - [Transitioning from RNNs to Transformer-based Models]()