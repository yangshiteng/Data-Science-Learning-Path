Hereâ€™s a **simple example** of how to **load a pretrained diffusion model** using Hugging Faceâ€™s ðŸ§¨ `diffusers` library and generate an image from a text prompt.

---

## âœ… Step-by-Step Example: Load Stable Diffusion

### ðŸ“¦ 1. Install Dependencies

Make sure you have the necessary packages:

```bash
pip install diffusers transformers torch accelerate safetensors
```

---

### ðŸ§  2. Load Pretrained Model from Hugging Face

```python
from diffusers import StableDiffusionPipeline
import torch

# Load Stable Diffusion v1.5 from Hugging Face
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to("cuda")
```

âœ… Make sure youâ€™re logged into Hugging Face (`huggingface-cli login`) if the model requires authentication.

---

### ðŸŽ¨ 3. Generate an Image

```python
prompt = "a cozy cabin in a snowy forest at night, high quality, detailed"
image = pipe(prompt).images[0]

# Show or save the image
image.show()
# image.save("output.png")
```

---

## ðŸ§ª Optional Variants

You can also try other models:

| Model Variant    | Example Code                |
| ---------------- | --------------------------- |
| **DDPM (small)** | `"google/ddpm-cifar10-32"`  |
| **DreamShaper**  | `"Lykon/DreamShaper"`       |
| **Deliberate**   | `"Lykon/deliberate"`        |
| **Anything-v5**  | `"andite/anything-v5.0"`    |
| **Anime Model**  | `"hakurei/waifu-diffusion"` |

Example:

```python
pipe = StableDiffusionPipeline.from_pretrained("hakurei/waifu-diffusion").to("cuda")
pipe("a cute anime girl with a dragon").images[0].show()
```

---

## ðŸ“Œ Summary

* Use `diffusers` and `from_pretrained()` to easily load pretrained diffusion models.
* You can generate images from simple prompts.
* Hugging Face hosts dozens of high-quality pretrained diffusion models.
